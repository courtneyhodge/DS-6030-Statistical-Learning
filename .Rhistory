# Initialize vectors to store MSE results for each simulation
#n_simulations <- 100
mse_linear <- numeric(n_simulations)
mse_quadratic <- numeric(n_simulations)
mse_cubic <- numeric(n_simulations)
# Run the simulation for each iteration
for (i in 1:n_simulations) {
# Generate new training data
x_train <- sim_x(n)
y_train <- sim_y(x_train, sd = sigma)
data_train <- tibble(x = x_train, y = y_train)
# Fit models: linear, quadratic, cubic
linear_model <- lm(y ~ poly(x, 1), data = data_train)
quadratic_model <- lm(y ~ poly(x, 2), data = data_train)
cubic_model <- lm(y ~ poly(x, 3), data = data_train)
# Calculate MSE for each model
mse_linear[i] <- calc_mse(linear_model, data_test)
mse_quadratic[i] <- calc_mse(quadratic_model, data_test)
mse_cubic[i] <- calc_mse(cubic_model, data_test)
}
#--part g, but I'm adding it here anyways
# Combine results into a data frame
mse_results <- tibble(
Simulation = 1:n_simulations,
Linear = mse_linear,
Quadratic = mse_quadratic,
Cubic = mse_cubic
)
# Determine the best model for each simulation and store the best MSE
mse_results <- mse_results %>%
rowwise() %>%
mutate(
Best_Model = case_when(
Linear == min(c(Linear, Quadratic, Cubic)) ~ "Linear",
Quadratic == min(c(Linear, Quadratic, Cubic)) ~ "Quadratic",
Cubic == min(c(Linear, Quadratic, Cubic)) ~ "Cubic"
),
Best_MSE = min(c(Linear, Quadratic, Cubic))
) %>%
ungroup()
# Count how many times each model was the best
best_model_count <- mse_results %>%
count(Best_Model)
# Return a list with detailed results
return(list(
mse_results = mse_results,
best_model_count = best_model_count
))
}
#-- Generate Test Data
ntest = 10000 # Number of test samples
sigma = 2
set.seed(612) # set *different* seed
xtest = sim_x(ntest) # generate test X's
ytest = sim_y(xtest, sd=sigma) # generate test Y's
data_test = tibble(x=xtest, y=ytest) # test data
simulation_result <- simulation_f(n_simulations = 100, sigma, data_test)
simulation_result$best_model_count
#-- Generate Test Data
ntest = 10000 # Number of test samples
sigma = 4
set.seed(612) # set *different* seed
xtest = sim_x(ntest) # generate test X's
ytest = sim_y(xtest, sd=sigma) # generate test Y's
data_test = tibble(x=xtest, y=ytest) # test data
simulation_result <- simulation_f(n_simulations = 300 , sigma, data_test)
simulation_result$best_model_count
simulation_f <- function(n, sigma, data_test){
set.seed(613)
# Function to calculate MSE
calc_mse <- function(model, data_test) {
y_pred <- predict(model, newdata = data_test)
mean((data_test$y - y_pred)^2)
}
# Initialize vectors to store MSE results for each simulation
#n_simulations <- 100
mse_linear <- numeric(n)
mse_quadratic <- numeric(n)
mse_cubic <- numeric(n)
# Run the simulation for each iteration
for (i in 1:n) {
# Generate new training data
x_train <- sim_x(n)
y_train <- sim_y(x_train, sd = sigma)
data_train <- tibble(x = x_train, y = y_train)
# Fit models: linear, quadratic, cubic
linear_model <- lm(y ~ poly(x, 1), data = data_train)
quadratic_model <- lm(y ~ poly(x, 2), data = data_train)
cubic_model <- lm(y ~ poly(x, 3), data = data_train)
# Calculate MSE for each model
mse_linear[i] <- calc_mse(linear_model, data_test)
mse_quadratic[i] <- calc_mse(quadratic_model, data_test)
mse_cubic[i] <- calc_mse(cubic_model, data_test)
}
#--part g, but I'm adding it here anyways
# Combine results into a data frame
mse_results <- tibble(
Simulation = 1:n,
Linear = mse_linear,
Quadratic = mse_quadratic,
Cubic = mse_cubic
)
# Determine the best model for each simulation and store the best MSE
mse_results <- mse_results %>%
rowwise() %>%
mutate(
Best_Model = case_when(
Linear == min(c(Linear, Quadratic, Cubic)) ~ "Linear",
Quadratic == min(c(Linear, Quadratic, Cubic)) ~ "Quadratic",
Cubic == min(c(Linear, Quadratic, Cubic)) ~ "Cubic"
),
Best_MSE = min(c(Linear, Quadratic, Cubic))
) %>%
ungroup()
# Count how many times each model was the best
best_model_count <- mse_results %>%
count(Best_Model)
# Return a list with detailed results
return(list(
mse_results = mse_results,
best_model_count = best_model_count
))
}
#-- Generate Test Data
ntest = 10000 # Number of test samples
sigma = 2
set.seed(612) # set *different* seed
xtest = sim_x(ntest) # generate test X's
ytest = sim_y(xtest, sd=sigma) # generate test Y's
data_test = tibble(x=xtest, y=ytest) # test data
simulation_result <- simulation_f(n = 100, sigma, data_test)
simulation_result$best_model_count
#-- Generate Test Data
ntest = 10000 # Number of test samples
sigma = 4
set.seed(612) # set *different* seed
xtest = sim_x(ntest) # generate test X's
ytest = sim_y(xtest, sd=sigma) # generate test Y's
data_test = tibble(x=xtest, y=ytest) # test data
simulation_result <- simulation_f(n= 300 , sigma, data_test)
simulation_result$best_model_count
ntest = 10000 # Number of test samples
sigma = 2
set.seed(612) # set *different* seed
xtest = sim_x(ntest) # generate test X's
ytest = sim_y(xtest, sd=sigma) # generate test Y's
data_test = tibble(x=xtest, y=ytest) # test data
simulation_result <- simulation_f(n= 300 , sigma, data_test)
simulation_result$best_model_count
ntest = 10000 # Number of test samples
sigma = 2
set.seed(612) # set *different* seed
xtest = sim_x(ntest) # generate test X's
ytest = sim_y(xtest, sd=sigma) # generate test Y's
data_test = tibble(x=xtest, y=ytest) # test data
simulation_result <- simulation_f(n= 100 , sigma, data_test)
simulation_result$best_model_count
#-- Generate Test Data
ntest = 10000 # Number of test samples
sigma = 2
set.seed(612) # set *different* seed
xtest = sim_x(ntest) # generate test X's
ytest = sim_y(xtest, sd=sigma) # generate test Y's
data_test = tibble(x=xtest, y=ytest) # test data
simulation_result <- simulation_f(n = 100, sigma, data_test)
simulation_result$best_model_count
ntest = 10000 # Number of test samples
sigma = 4
set.seed(612) # set *different* seed
xtest = sim_x(ntest) # generate test X's
ytest = sim_y(xtest, sd=sigma) # generate test Y's
data_test = tibble(x=xtest, y=ytest) # test data
simulation_result <- simulation_f(n= 100 , sigma, data_test)
simulation_result$best_model_count
ntest = 10000 # Number of test samples
sigma = 6
set.seed(612) # set *different* seed
xtest = sim_x(ntest) # generate test X's
ytest = sim_y(xtest, sd=sigma) # generate test Y's
data_test = tibble(x=xtest, y=ytest) # test data
simulation_result <- simulation_f(n= 100 , sigma, data_test)
simulation_result$best_model_count
ntest = 10000 # Number of test samples
sigma = 8
set.seed(612) # set *different* seed
xtest = sim_x(ntest) # generate test X's
ytest = sim_y(xtest, sd=sigma) # generate test Y's
data_test = tibble(x=xtest, y=ytest) # test data
simulation_result <- simulation_f(n= 100 , sigma, data_test)
simulation_result$best_model_count
ntest = 10000 # Number of test samples
sigma = 1
set.seed(612) # set *different* seed
xtest = sim_x(ntest) # generate test X's
ytest = sim_y(xtest, sd=sigma) # generate test Y's
data_test = tibble(x=xtest, y=ytest) # test data
simulation_result <- simulation_f(n= 100 , sigma, data_test)
simulation_result$best_model_count
ntest = 10000 # Number of test samples
sigma = 1
set.seed(612) # set *different* seed
xtest = sim_x(ntest) # generate test X's
ytest = sim_y(xtest, sd=sigma) # generate test Y's
data_test = tibble(x=xtest, y=ytest) # test data
simulation_result <- simulation_f(n= 100 , sigma, data_test)
simulation_result$best_model_count
ntest = 10000 # Number of test samples
sigma = 5
set.seed(612) # set *different* seed
xtest = sim_x(ntest) # generate test X's
ytest = sim_y(xtest, sd=sigma) # generate test Y's
data_test = tibble(x=xtest, y=ytest) # test data
simulation_result <- simulation_f(n= 100 , sigma, data_test)
simulation_result$best_model_count
ntest = 10000 # Number of test samples
sigma = 8
set.seed(612) # set *different* seed
xtest = sim_x(ntest) # generate test X's
ytest = sim_y(xtest, sd=sigma) # generate test Y's
data_test = tibble(x=xtest, y=ytest) # test data
simulation_result <- simulation_f(n= 300 , sigma, data_test)
simulation_result$best_model_count
#-- Generate Test Data
ntest = 10000 # Number of test samples
sigma = 2
set.seed(612) # set *different* seed
xtest = sim_x(ntest) # generate test X's
ytest = sim_y(xtest, sd=sigma) # generate test Y's
data_test = tibble(x=xtest, y=ytest) # test data
simulation_result <- simulation_f(n = 100, sigma, data_test)
simulation_result$best_model_count
#-- Generate Test Data
ntest = 10000 # Number of test samples
sigma = 100
set.seed(612) # set *different* seed
xtest = sim_x(ntest) # generate test X's
ytest = sim_y(xtest, sd=sigma) # generate test Y's
data_test = tibble(x=xtest, y=ytest) # test data
simulation_result <- simulation_f(n = 100, sigma, data_test)
simulation_result$best_model_count
linear_model <- lm(y~poly(x,1), data = data_train)
quadratic_model <-lm(y~poly(x,2), data = data_train)
cubic_model <-lm(y~poly(x,3), data=data_train)
x_seq <- seq(min(data_train$x), max(data_train$x), length.out = 100)
# Assuming sim_y without error (sd=0) represents the true quadratic model
y_true <- sim_y(x_seq, sd = 0)  # True quadratic model without noise
linear_model <- lm(y~poly(x,1), data = data_train)
quadratic_model <-lm(y~poly(x,2), data = data_train)
cubic_model <-lm(y~poly(x,3), data=data_train)
x_seq <- seq(min(data_train$x), max(data_train$x), length.out = 100)
# Assuming sim_y without error (sd=0) represents the true quadratic model
y_true <- sim_y(x_seq, sd = 0)  # True quadratic model without noise
y_linear_pred <- predict(linear_model, newdata = data.frame(x = x_seq))
y_quadratic_pred <- predict(quadratic_model, newdata = data.frame(x = x_seq))
y_cubic_pred <- predict(cubic_model, newdata = data.frame(x = x_seq))
# Create a sequence of x values for plotting the fitted lines
x_seq <- seq(min(data_train$x), max(data_train$x), length.out = 100)
# Combine the predicted values into one data frame for plotting
fit_data <- tibble(
x = rep(x_seq, 4),
y = c(y_linear_pred, y_quadratic_pred, y_cubic_pred, y_true),
model = factor(rep(c("Linear Model", "Quadratic Model", "Cubic Model", "True Model"), each = 100))
)
# Create the ggplot
ggplot(data_train, aes(x = x, y = y)) +
geom_point() +  # Scatter plot of the data
geom_line(data = fit_data, aes(x = x, y = y, color = model)) +  # Fitted lines
labs(title = "Polynomial Regression Models", x = "x", y = "y") +
scale_color_manual(values = c("red", "blue", "purple", "green")) +
scale_x_continuous(breaks=seq(0, 1, by=.10)) +
scale_y_continuous(breaks=seq(-6, 10, by=2))
setwd("C:/Users/hodge/Desktop/UVA_Coding_Folder/DS-6030-Statistical-Learning/Homework")
setwd("C:/Users/hodge/Desktop/UVA_Coding_Folder/DS-6030-Statistical-Learning")
# Create a sequence of x values for plotting the fitted lines
x_seq <- seq(min(data_train$x), max(data_train$x), length.out = 100)
# Combine the predicted values into one data frame for plotting
fit_data <- tibble(
x = rep(x_seq, 4),
y = c(y_linear_pred, y_quadratic_pred, y_cubic_pred, y_true),
model = factor(rep(c("Linear Model", "Quadratic Model", "Cubic Model", "True Model"), each = 100))
)
sim_x <- function(n) runif(n)         #U[0,1]
f <-function(x) -1 + 0.5*x + 0.2*x^2  #true mean function
sim_y <- function(x, sd) {            #generate Y|X from N{f(x), sd}
n = length(x)
f(x) + rnorm(n, mean = 0, sd = sd)
}
#| message: false
#| warning: false
library(tidyverse) # functions for data manipulation
library(tibble)
sim_x <- function(n) runif(n)         #U[0,1]
f <-function(x) -1 + 0.5*x + 0.2*x^2  #true mean function
sim_y <- function(x, sd) {            #generate Y|X from N{f(x), sd}
n = length(x)
f(x) + rnorm(n, mean = 0, sd = sd)
}
#-- Settings
n = 100       #number of observations
sd = 3        #stdev for error
set.seed(611) # set seed for reproducibility
x = sim_x(n)  # get x values
y = sim_y(x, sd = sd) # get y values
data_train = tibble(x, y) # training data tibble
#----------DELETE ME-------------#
#-- Generate Test Data
ntest = 50000 # Number of test samples
set.seed(611) # set *different* seed
xtest = sim_x(ntest) # generate test X's
ytest = sim_y(xtest, sd=sd) # generate test Y's
data_test = tibble(x=xtest, y=ytest) # test data
#-- plot points and true regression function
scatter_plot <- ggplot(data_train, aes(x,y)) +
geom_point() +
geom_function(fun = f) +
scale_x_continuous(breaks=seq(0, 1, by=.10)) +
scale_y_continuous(breaks=seq(-6, 10, by=2))
scatter_plot
linear_model <- lm(y~poly(x,1), data = data_train)
quadratic_model <-lm(y~poly(x,2), data = data_train)
cubic_model <-lm(y~poly(x,3), data=data_train)
x_seq <- seq(min(data_train$x), max(data_train$x), length.out = 100)
# Assuming sim_y without error (sd=0) represents the true quadratic model
y_true <- sim_y(x_seq, sd = 0)  # True quadratic model without noise
y_linear_pred <- predict(linear_model, newdata = data.frame(x = x_seq))
y_quadratic_pred <- predict(quadratic_model, newdata = data.frame(x = x_seq))
y_cubic_pred <- predict(cubic_model, newdata = data.frame(x = x_seq))
# Create a sequence of x values for plotting the fitted lines
x_seq <- seq(min(data_train$x), max(data_train$x), length.out = 100)
# Combine the predicted values into one data frame for plotting
fit_data <- tibble(
x = rep(x_seq, 4),
y = c(y_linear_pred, y_quadratic_pred, y_cubic_pred, y_true),
model = factor(rep(c("Linear Model", "Quadratic Model", "Cubic Model", "True Model"), each = 100))
)
# Create the ggplot
ggplot(data_train, aes(x = x, y = y)) +
geom_point() +  # Scatter plot of the data
geom_line(data = fit_data, aes(x = x, y = y, color = model)) +  # Fitted lines
labs(title = "Polynomial Regression Models", x = "x", y = "y") +
scale_color_manual(values = c("red", "blue", "purple", "green"))
# Create a sequence of x values for plotting the fitted lines
x_seq <- seq(min(data_train$x), max(data_train$x), length.out = 100)
# Combine the predicted values into one data frame for plotting
fit_data <- tibble(
x = rep(x_seq, 4),
y = c(y_linear_pred, y_quadratic_pred, y_cubic_pred, y_true),
model = factor(rep(c("Linear Model", "Quadratic Model", "Cubic Model", "True Model"), each = 100))
)
# Create the ggplot
ggplot(data_train, aes(x = x, y = y)) +
geom_point() +  # Scatter plot of the data
geom_line(data = fit_data, aes(x = x, y = y, color = model)) +  # Fitted lines
labs(title = "Polynomial Regression Models", x = "x", y = "y") +
scale_color_manual(values = c("red", "blue", "purple", "green")) +
scale_x_continuous(breaks=seq(0, 1, by=.10)) +
scale_y_continuous(breaks=seq(-6, 10, by=2))
# Create a sequence of x values for plotting the fitted lines
x_seq <- seq(min(data_train$x), max(data_train$x), length.out = 100)
# Combine the predicted values into one data frame for plotting
fit_data <- tibble(
x = rep(x_seq, 4),
y = c(y_linear_pred, y_quadratic_pred, y_cubic_pred, y_true),
model = factor(rep(c("Linear Model", "Quadratic Model", "Cubic Model", "True Model"), each = 100))
)
# Create the ggplot
ggplot(data_train, aes(x = x, y = y)) +
geom_point() +  # Scatter plot of the data
geom_line(data = fit_data, aes(x = x, y = y, color = model)) +  # Fitted lines
labs(title = "Polynomial Regression Models", x = "x", y = "y") +
scale_color_manual(values = c("red", "blue", "purple", "green")) +
scale_x_continuous(breaks=seq(0, 2, by=.50)) +
scale_y_continuous(breaks=seq(-6, 10, by=2))
# Create a sequence of x values for plotting the fitted lines
x_seq <- seq(min(data_train$x), max(data_train$x), length.out = 100)
# Combine the predicted values into one data frame for plotting
fit_data <- tibble(
x = rep(x_seq, 4),
y = c(y_linear_pred, y_quadratic_pred, y_cubic_pred, y_true),
model = factor(rep(c("Linear Model", "Quadratic Model", "Cubic Model", "True Model"), each = 100))
)
# Create the ggplot
ggplot(data_train, aes(x = x, y = y)) +
geom_point() +  # Scatter plot of the data
geom_line(data = fit_data, aes(x = x, y = y, color = model)) +  # Fitted lines
labs(title = "Polynomial Regression Models", x = "x", y = "y") +
scale_color_manual(values = c("red", "blue", "purple", "green")) +
scale_x_continuous(breaks=seq(0, 2)) +
scale_y_continuous(breaks=seq(-6, 10, by=2))
# Create a sequence of x values for plotting the fitted lines
x_seq <- seq(min(data_train$x), max(data_train$x), length.out = 100)
# Combine the predicted values into one data frame for plotting
fit_data <- tibble(
x = rep(x_seq, 4),
y = c(y_linear_pred, y_quadratic_pred, y_cubic_pred, y_true),
model = factor(rep(c("Linear Model", "Quadratic Model", "Cubic Model", "True Model"), each = 100))
)
# Create the ggplot
ggplot(data_train, aes(x = x, y = y)) +
geom_point() +  # Scatter plot of the data
geom_line(data = fit_data, aes(x = x, y = y, color = model)) +  # Fitted lines
labs(title = "Polynomial Regression Models", x = "x", y = "y") +
scale_color_manual(values = c("red", "blue", "purple", "green")) +
scale_x_continuous(breaks=seq(0, 2, by=.10)) +
scale_y_continuous(breaks=seq(-6, 10, by=2))
# Create a sequence of x values for plotting the fitted lines
x_seq <- seq(min(data_train$x), max(data_train$x), length.out = 100)
# Combine the predicted values into one data frame for plotting
fit_data <- tibble(
x = rep(x_seq, 4),
y = c(y_linear_pred, y_quadratic_pred, y_cubic_pred, y_true),
model = factor(rep(c("Linear Model", "Quadratic Model", "Cubic Model", "True Model"), each = 100))
)
# Create the ggplot
ggplot(data_train, aes(x = x, y = y)) +
geom_point() +  # Scatter plot of the data
geom_line(data = fit_data, aes(x = x, y = y, color = model)) +  # Fitted lines
labs(title = "Polynomial Regression Models", x = "x", y = "y") +
scale_color_manual(values = c("red", "blue", "purple", "green")) +
scale_x_continuous(breaks=seq(0, 3, by=.10)) +
scale_y_continuous(breaks=seq(-6, 10, by=2))
# Create a sequence of x values for plotting the fitted lines
x_seq <- seq(min(data_train$x), max(data_train$x), length.out = 100)
# Combine the predicted values into one data frame for plotting
fit_data <- tibble(
x = rep(x_seq, 4),
y = c(y_linear_pred, y_quadratic_pred, y_cubic_pred, y_true),
model = factor(rep(c("Linear Model", "Quadratic Model", "Cubic Model", "True Model"), each = 100))
)
# Create the ggplot
ggplot(data_train, aes(x = x, y = y)) +
geom_point() +  # Scatter plot of the data
geom_line(data = fit_data, aes(x = x, y = y, color = model)) +  # Fitted lines
labs(title = "Polynomial Regression Models", x = "x", y = "y") +
scale_color_manual(values = c("red", "blue", "purple", "green"))
linear_model <- lm(y~poly(x,1), data = data_train)
quadratic_model <-lm(y~poly(x,2), data = data_train)
cubic_model <-lm(y~poly(x,3), data=data_train)
x_seq <- seq(min(data_train$x), max(data_train$x), length.out = 100)
# Assuming sim_y without error (sd=0) represents the true quadratic model
y_true <- sim_y(x_seq, sd = 0)  # True quadratic model without noise
y_linear_pred <- predict(linear_model, newdata = data.frame(x = x_seq))
y_quadratic_pred <- predict(quadratic_model, newdata = data.frame(x = x_seq))
y_cubic_pred <- predict(cubic_model, newdata = data.frame(x = x_seq))
# Create a sequence of x values for plotting the fitted lines
x_seq <- seq(min(data_train$x), max(data_train$x), length.out = 100)
# Combine the predicted values into one data frame for plotting
fit_data <- tibble(
x = rep(x_seq, 4),
y = c(y_linear_pred, y_quadratic_pred, y_cubic_pred, y_true),
model = factor(rep(c("Linear Model", "Quadratic Model", "Cubic Model", "True Model"), each = 100))
)
# Create the ggplot
ggplot(data_train, aes(x = x, y = y)) +
geom_point() +  # Scatter plot of the data
geom_line(data = fit_data, aes(x = x, y = y, color = model)) +  # Fitted lines
labs(title = "Polynomial Regression Models", x = "x", y = "y") +
scale_color_manual(values = c("red", "blue", "purple", "green"))
# Create a sequence of x values for plotting the fitted lines
x_seq <- seq(min(data_train$x), max(data_train$x), length.out = 100)
# Combine the predicted values into one data frame for plotting
fit_data <- tibble(
x = rep(x_seq, 4),
y = c(y_linear_pred, y_quadratic_pred, y_cubic_pred, y_true),
model = factor(rep(c("Linear Model", "Quadratic Model", "Cubic Model", "True Model"), each = 100))
)
# Create the ggplot
ggplot(data_train, aes(x = x, y = y)) +
geom_point() +  # Scatter plot of the data
geom_line(data = fit_data, aes(x = x, y = y, color = model)) +  # Fitted lines
labs(title = "Polynomial Regression Models", x = "x", y = "y") +
scale_color_manual(values = c("red", "blue", "purple", "green")) +
scale_x_continuous(breaks=seq(-2, 2, by=.10)) +
scale_y_continuous(breaks=seq(-6, 10, by=2))
# Create a sequence of x values for plotting the fitted lines
x_seq <- seq(min(data_train$x), max(data_train$x), length.out = 100)
# Combine the predicted values into one data frame for plotting
fit_data <- tibble(
x = rep(x_seq, 4),
y = c(y_linear_pred, y_quadratic_pred, y_cubic_pred, y_true),
model = factor(rep(c("Linear Model", "Quadratic Model", "Cubic Model", "True Model"), each = 100))
)
# Create the ggplot
ggplot(data_train, aes(x = x, y = y)) +
geom_point() +  # Scatter plot of the data
geom_line(data = fit_data, aes(x = x, y = y, color = model)) +  # Fitted lines
labs(title = "Polynomial Regression Models", x = "x", y = "y") +
scale_color_manual(values = c("red", "blue", "purple", "green")) +
scale_x_continuous(breaks=seq(-2, 2, by=.10), limits = c(-4,4)) +
scale_y_continuous(breaks=seq(-6, 10, by=2))
# Create a sequence of x values for plotting the fitted lines
x_seq <- seq(min(data_train$x), max(data_train$x), length.out = 100)
# Combine the predicted values into one data frame for plotting
fit_data <- tibble(
x = rep(x_seq, 4),
y = c(y_linear_pred, y_quadratic_pred, y_cubic_pred, y_true),
model = factor(rep(c("Linear Model", "Quadratic Model", "Cubic Model", "True Model"), each = 100))
)
# Create the ggplot
ggplot(data_train, aes(x = x, y = y)) +
geom_point() +  # Scatter plot of the data
geom_line(data = fit_data, aes(x = x, y = y, color = model)) +  # Fitted lines
labs(title = "Polynomial Regression Models", x = "x", y = "y") +
scale_color_manual(values = c("red", "blue", "purple", "green"))
sim_x <- function(n) runif(n)         #U[0,1]
f <-function(x) 1 + 2*x + 5*sin(5*x) 2  #true mean function
#| message: false
#| warning: false
library(tidyverse) # functions for data manipulation
library(tibble)
library(FNN)
install.packages("FNN")
