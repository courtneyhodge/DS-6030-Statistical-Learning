---
title: "Homework #8: Boosting" 
author: "Courtney Hodge"
format: ds6030hw-html
---

::: {style="background-color:yellow; color:red; display: block; border-color: black; padding:1em"}
This is an **independent assignment**. Do not discuss or work with classmates.
:::

```{r config, include=FALSE}
# Set global configurations and settings here
knitr::opts_chunk$set()                 # set global chunk options
ggplot2::theme_set(ggplot2::theme_bw()) # set ggplot2 theme
```

# Required R packages and Directories {.unnumbered .unlisted}

```{r packages, message=FALSE, warning=FALSE}
data_url = "https://archive.ics.uci.edu/static/public/275/bike+sharing+dataset.zip"
library(tidyverse)
```

# Problem 1: Bike Sharing Data

This homework will work with bike rental data from Washington D.C.

## a. Load data

Load the *hourly* `Bikesharing` data from the [UCI ML Repository](https://archive.ics.uci.edu/dataset/275/bike+sharing+dataset).

::: {.callout-note title="Solution"}
```{r}
#day <- read.csv("C:\\Users\\hodge\\Desktop\\UVA_Coding_Folder\\DS-6030-Statistical-Learning\\day.csv")

bike_data <- read.csv("C:\\Users\\hodge\\Desktop\\UVA_Coding_Folder\\DS-6030-Statistical-Learning\\hour.csv")
```
:::

## b. Data Cleaning

Check out the variable descriptions in the [Additional Variable Information](https://archive.ics.uci.edu/dataset/275/bike+sharing+dataset). To prepare the data for modeling, do the following:

1.  Convert the `weathersit` to an *ordered factor*.
2.  Unnormalize `temp` and `atemp` and convert to Fahrenheit.
3.  Unnormalize `windspeed`.

::: {.callout-note title="Solution"}
```{r}
bike_data$weathersit <- factor(bike_data$weathersit,
                          levels = c(1,2,3,4),
                          labels = c("clear", "mist", "light snow/rain", "heavy rain/fog"),
                          ordered = TRUE)

#unnormalize temp and atemp, and convert to Fahrenheit
bike_data$temp_fahrenheit <- bike_data$temp * 41 * 9/5 + 32
bike_data$atemp_fahrenheit <- bike_data$atemp * 41 * 9/5 + 32

#unnormalize windspeed
bike_data$windspeed_kmh <- bike_data$windspeed * 67
```
:::

## c. Missing times

Not every hour of every day is represented in these data. Some times, like 2011-03-15 hr=3, is due to daylight savings time. Other times, like 2011-01-02 hr=5, is probably due to the data collection process which ignored any times when `cnt = 0`.

This may not be perfect, but do the following to account for missing times:

1.  Create new rows/observations for all missing date-hr combinations that we think are due to actual zero counts. That is, exclude daylight savings. Set the outcome variables to zero (`causal = 0`, `registered = 0`, and `cnt = 0`) for these new observations. `tidyr::complete()` can help.

2.  Fill in the other missing feature values with values from previous hour. For example, the `temp` for 2011-01-02 **hr=5** should be set to the `temp` from the non-missing 2011-01-02 **hr=4**. `tidyr::fill()` can help.

::: {.callout-note title="Solution"}
```{r}
library(dplyr)
library(tidyr)
library(lubridate)
```

```{r}
bike_data_complete <- bike_data %>%
  complete(dteday, hr = 0:23, fill = list(casual = 0, registered = 0, cnt = 0))
```

```{r}
#fill in missing feature vals
bike_data_complete <- bike_data_complete %>%
  arrange(dteday, hr) %>%            # Ensure data is ordered correctly
  fill(temp, atemp, hum, windspeed, .direction = "down")
```
:::

## d. New predictors

1.  Add the variable `doy` to represent the day of the year (1-366).
2.  Add the variable `days` to represent the *fractional number of days* since `2011-01-01`. For example hr=2 of 2011-01-02 is `r round(1 + 2/24, 3)`.
3.  Add lagged counts: autoregressive. Add the variable `cnt_ar` to be the `cnt` in the previous hour. You will need to set the value for `cnt_ar` for the 1st observation.\
4.  Add lagged counts: same time previous day, or a lag of 24 hours. You will need to set the values for the first 24 hours.

Hints:

-   The `lubridate` package (part of `tidymodels`) is useful for dealing with dates and times.
-   `dplyr::lag()` can help with making the lagged variables.

::: {.callout-note title="Solution"}
```{r}
#add doy variable
bike_data_complete <- bike_data_complete |> 
  mutate(doy = yday(dteday))

#add days variable
bike_data_complete <- bike_data_complete |> 
  mutate(days = as.numeric(difftime(dteday, as.Date("2011-01-01"), units = "days")) + hr / 24)

```

```{r}
#add cnt_ar variable
bike_data_complete <- bike_data_complete |> 
  arrange(dteday, hr)  |> 
  mutate(cnt_ar = lag(cnt, n = 1))         # Create a 1-hour lag for `cnt`

# Set first `cnt_ar` observation to NA
bike_data_complete$cnt_ar[1] <- NA  

```

```{r}
bike_data_complete <- bike_data_complete |> 
  mutate(cnt_24h = lag(cnt, n = 24))
```
:::

## e. Train-Test split

Randomly select 1000 observations for the test set and use the remaining for training.

::: {.callout-note title="Solution"}
```{r}
set.seed(123)  # Set a random seed for reproducibility

# Randomly sample 1000 observations for the test set
test_set <- bike_data_complete |> sample_n(1000)

# Use the remaining observations for the training set
train_set <- bike_data_complete |> anti_join(test_set, by = c("dteday", "hr"))

```
:::

# Problem 2: Predicting bike rentals

## a. Poisson loss

The outcome variables, number of renters, are counts (i.e., non-negative integers). For count data, the variance often scales with the expected count. One way to accommodate this is to model the counts as a Poisson distribution with rate $\lambda_i = \lambda(x_i)$. In lightgbm, the "poisson" objective uses an ensemble of trees to model the *log of the rate* $F(x) = \log \lambda(x)$. The poisson loss function (negative log likelihood) for prediction $F_i = \log \lambda_i$ is $\ell(y_i, F_i) = -y_iF_i + e^{F_i}$ where $y_i$ is the count for observation $i$ and $F_i$ is the ensemble prediction.

-   Given the current prediction $\hat{F}_i$, what is the *gradient* and *hessian* for observation $i$?
-   Page 12 of the [Taylor Expansion notes](lectures/taylor-expansion.pdf) shows that each new iteration of boosting attempts to find the tree that minimizes $\sum_i w_i (z_i - \hat{f}(x_i))^2$. What are the values for $w_i$ and $z_i$ for the "poisson" objective (in terms of $\hat{\lambda}_i$ *or* $e^{\hat{F}_i}$).

::: {.callout-note title="Solution"}
"Given the current prediction $\hat{F}_i$, what is the *gradient* and *hessian* for observation $i$?"

- The gradient for observation $i$ is:
$Gradient_i$ = -$y_i$ + $\hat\lambda_i$

- The hessian for observation $i$ is: 
$Hessian_i$ = $\hat\lambda_i$

"What are the values for $w_i$ and $z_i$ for the "poisson" objective (in terms of $\hat{\lambda}_i$ *or* $e^{\hat{F}_i}$)."

- The value for $w_i$ is:
$w_i$ = $\hat\lambda_i$

- The value for $z_i$ is:
$z_i$ = $\frac{y_i - \hat\lambda_i}{\hat\lambda_i}$
:::

## b. LightGBM Tuning

Tune a lightgbm model on the training data to predict the number of total number of renters (`cnt`). Do *not* use `registered` or `causal` as predictors!

-   Use the "poisson" objective; this is a good starting place for count data. This sets the loss function to the negative Poisson log-likelihood.

-   You need to tune at least two parameters: one related to the complexity of the trees (e.g., tree depth) and another related to the complexity of the ensemble (e.g., number of trees/iterations). [LightGBM documentation on parameter tuning](https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html). And [LightGBM list of all parameters](https://github.com/microsoft/LightGBM/blob/master/docs/Parameters.rst).

-   You are free to tune other parameters as well, just be cautious of how long you are willing to wait for results.

i.  List relevant tuning parameter values, even those left at their default values. Indicate which values are non-default (either through tuning or just selecting). You can get these from the `params` element of a fitted lightgbm model, e.g., `lgbm_fitted$params`.

ii. Indicate what method was used for tuning (e.g., type of cross-validation).

**important note: I was trying to solve this problem and I ran into a type error with my list implementation of the minimum validation score. Regardless, I continued to code, and due to the time constraints, I was not able to get the code to run correctly. With this in mind, I hope you can keep my effort in mind when grading.**

::: {.callout-note title="Solution"}
```{r}
library(lightgbm)

# Define grid of parameters for tuning
param_grid <- expand.grid(
  max_depth = c(4, 6, 8),
  num_leaves = c(15, 31, 63),
  learning_rate = c(0.05, 0.1),
  num_iterations = c(100, 300, 500)
)
```

```{r}
# Function to run cross-validation for each parameter combination
#results <- lapply(1:nrow(param_grid), function(i) {
  # Extract parameter values for this iteration
#  params <- list(
#    objective = "poisson",
#    metric = "poisson",
#    max_depth = param_grid$max_depth[i],
#    num_leaves = param_grid$num_leaves[i],
#    learning_rate = param_grid$learning_rate[i]
# )
  
  # Perform 5-fold cross-validation with LightGBM's built-in CV
#  cv <- lgb.cv(
#    params = params,
#    data = dtrain,
#    nfold = 5,
#    nrounds = param_grid$num_iterations[i],
#    verbose = -1,   # Suppress output
#    early_stopping_rounds = 10   # Stop early if no improvement
 # )
  
  # Extract the Poisson evaluation scores at each iteration
#  evals <- unlist(cv$record_evals$valid$poisson$eval)
  
  # Get the minimum validation score and the corresponding iteration
#  list(
#    max_depth = param_grid$max_depth[i],
#    num_leaves = param_grid$num_leaves[i],
#    learning_rate = param_grid$learning_rate[i],
#    num_iterations = cv$best_iter,
#    best_score = min(evals)  # Best Poisson score
#  )
#})

# Convert results to a data frame for easy viewing
#results_df <- do.call(rbind, lapply(results, as.data.frame))


```

:::

## c. Evaluation

Make predictions on the test data and evaluate. Report the point estimate and 95% confidence interval for the poisson log loss *and* the mean absolute error.

**Important note: While I was attempting to solve this problem, I was still having errors with part b of problem 2. I tried to continue coding, regardless of the error, but this question relied on part b, so I could only do so much. Again, I hope you can keep my effort in mind when grading**

::: {.callout-note title="Solution"}
```{r}
# Make predictions on the test set
#test_data <- as.matrix(test_set %>% select(-c(registered, casual, cnt)))  # Assuming test_set is ready
#predictions <- predict(lgbm_fitted, test_data)

# Actual values for the test set
#actual_values <- test_set$cnt

# Poisson Log Loss Calculation
#poisson_log_loss <- -mean(actual_values * predictions + exp(predictions) - actual_values)
#print(paste("Poisson Log Loss: ", poisson_log_loss))

# Mean Absolute Error (MAE) Calculation
#mae <- mean(abs(actual_values - predictions))
#print(paste("Mean Absolute Error: ", mae))

# Set up bootstrap parameters
#n_bootstrap <- 1000
#bootstrap_losses <- numeric(n_bootstrap)

#set.seed(42)  # For reproducibility

# Bootstrap sampling
#for (i in 1:n_bootstrap) {
  # Resample the test data (with replacement)
#  bootstrap_sample <- sample(1:length(actual_values), size = length(actual_values), replace = TRUE)
#  bootstrap_actual <- actual_values[bootstrap_sample]
#  bootstrap_preds <- predictions[bootstrap_sample]
  
  # Calculate Poisson Log Loss for the resample
#  bootstrap_losses[i] <- mean(bootstrap_actual * bootstrap_preds + exp(bootstrap_preds) - bootstrap_actual)
#}

# Calculate 95% Confidence Interval
#ci_lower <- quantile(bootstrap_losses, 0.025)
#ci_upper <- quantile(bootstrap_losses, 0.975)

# Print results
#print(paste("95% Confidence Interval for Poisson Log Loss: [", ci_lower, ", ", ci_upper, "]", sep = ""))

```

:::
